{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Dependencies/Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "import json\n",
    "from difflib import get_close_matches\n",
    "import json\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, AdamW, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch.nn.functional as F\n",
    "#import nltk\n",
    "#from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book1 => Rules of Play - Game Design Fundamentals\n",
    "\n",
    "Book2 => Game Design Workshop A Playcentric Approach to Creating Innovative Games\n",
    "\n",
    "Book3 => The Art of Game Design A Book of Lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PdfReader class from the pdfplumber module to read the PDF file 'Book1.pdf'\n",
    "pdf1 = PdfReader('Book1.pdf')\n",
    "\n",
    "# pdf2 = PdfReader('Book2.pdf')\n",
    "# pdf3 = PdfReader('Book3.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1_data = []\n",
    "\n",
    "# Iterate over each page in the PDF\n",
    "for page in pdf1.pages:\n",
    "    \n",
    "    # Extract the text from the page and append it to the list\n",
    "    pdf1_data.append(page.extract_text())\n",
    "\n",
    "# Test to see if the data is being read correctly\n",
    "#print(pdf1_data[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf2_data = []\n",
    "# for page in pdf2.pages:\n",
    "#     pdf2_data.append(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf3_data = []\n",
    "# for page in pdf3.pages:\n",
    "#     pdf3_data.append(page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_word(word, pdf_data):\n",
    "\n",
    "    # Initialize a counter for the word\n",
    "    count = 0\n",
    "\n",
    "    # Iterate over each page in the PDF data\n",
    "    for page in pdf_data:\n",
    "\n",
    "        # Increment the counter by the number of occurrences of the word in the page\n",
    "        count += page.lower().count(word)\n",
    "\n",
    "    # Return the total count of the word in the PDF data\n",
    "    return count\n",
    "\n",
    "# Test the function with the word 'game' and the first PDF data\n",
    "#print(search_word('game', pdf1_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to answer a question based on a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to answer a question based on a given text\n",
    "def answer_question(question, text):\n",
    "    # Specify the model name\n",
    "    model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'  # replace with the model of your choice\n",
    "    \n",
    "    # Load the tokenizer and model from the Hugging Face Model Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the question and text, and prepare the inputs for the model\n",
    "    inputs = tokenizer(question, text, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Feed the inputs to the model\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Get the start and end scores from the model outputs\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    # Find the start and end indices of the answer in the input_ids\n",
    "    start_index = torch.argmax(start_scores)\n",
    "    end_index = torch.argmax(end_scores)\n",
    "\n",
    "    # Convert the answer from token ids to string\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][start_index:end_index+1]))\n",
    "    \n",
    "    # Return the answer\n",
    "    return answer\n",
    "\n",
    "# Test the function with a question and a text\n",
    "#print(answer_question('Is this book for game developers?', pdf1_data[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Base Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the knowledge_base.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_knowledge_base(file_path: str) -> dict:\n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "\n",
    "        # Use the json.load function to load the data from the file\n",
    "        data: dict = json.load(file)\n",
    "        \n",
    "    # Return the loaded data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to the knowledge_base.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_knowledge_base(file_path: str, data: dict):\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(file_path, 'w') as file:\n",
    "\n",
    "        # Use the json.dump function to write the data to the file\n",
    "        # The indent parameter is 2 for pretty printing\n",
    "        json.dump(data, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the similarity b/w input and knowledge base to give best response\n",
    "\n",
    "\"cutoff\" can be varied to change similarity threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match(user_question: str, questions: list[str]) -> str | None:\n",
    "\n",
    "    # Use the get_close_matches function from the difflib module to find the closest matches\n",
    "    matches = get_close_matches(user_question, questions, n=1, cutoff=0.6)\n",
    "    \n",
    "    # If no matches are found, return None\n",
    "    if not matches:\n",
    "        return None\n",
    "    \n",
    "    # Otherwise, return the first (and only) match\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking an answer from the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question: str, knowledge_base: dict) -> str | None:\n",
    "    \n",
    "    # Iterate over the questions in the knowledge base\n",
    "    for i in knowledge_base[\"questions\"]:\n",
    "\n",
    "        # If the current question matches the input question\n",
    "        if i[\"question\"] == question:\n",
    "\n",
    "            # Return the answer to the current question\n",
    "            return i[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacting with the knowledge base and bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot():\n",
    "    knowledge_base: dict = load_knowledge_base('knowledge_base.json')\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input: str = input('You: ')\n",
    "\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        # Answer the user's question using the knowledge base\n",
    "        answer = answer_question(user_input, knowledge_base)\n",
    "\n",
    "        # If the bot knows the answer, provide it\n",
    "        if answer:\n",
    "            # Add the user's question and answer to the knowledge base\n",
    "            knowledge_base[\"questions\"].append({\"question\": user_input, \"answer\": answer})\n",
    "            save_knowledge_base('knowledge_base.json', knowledge_base)\n",
    "            print(f'Bot: {answer}')\n",
    "        else:\n",
    "            # If the bot doesn't know the answer, ask the user to teach it\n",
    "            print('Bot: I don\\'t know the answer. Can you teach me?')\n",
    "            new_answer: str = input('Type the answer or \"skip\" to skip: ')\n",
    "\n",
    "            if new_answer.lower() != 'skip':\n",
    "                # Add the user's question and answer to the knowledge base\n",
    "                knowledge_base[\"questions\"].append({\"question\": user_input, \"answer\": new_answer})\n",
    "                save_knowledge_base('knowledge_base.json', knowledge_base)\n",
    "                print('Bot: Thank you! I learned this new response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also manually add questions to the bot so that it can have a larger knowledge base or have a function add them for us from sources such as our three books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chat bot\n",
    "chat_bot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run gui.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
